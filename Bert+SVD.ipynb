{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe080be-6b0c-45cf-83e0-cdd65f7dbf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmr12\\AppData\\Local\\Temp\\ipykernel_1396\\2186912609.py:20: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv('Books.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVD model...\n",
      "Getting BERT embeddings for book titles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing titles:   0%|                                                                      | 0/3899 [00:00<?, ?it/s]D:\\Tools\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Tokenizing titles: 100%|███████████████████████████████████████████████████████████| 3899/3899 [01:17<00:00, 50.23it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Step 1: Load data\n",
    "print(\"Loading dataset...\")\n",
    "books = pd.read_csv('Books.csv')\n",
    "ratings = pd.read_csv('Ratings.csv')\n",
    "\n",
    "# 1. Retain users with enough ratings (at least 5 ratings)\n",
    "user_counts = ratings['User-ID'].value_counts()\n",
    "active_users = user_counts[user_counts >= 5].index\n",
    "filtered_ratings = ratings[ratings['User-ID'].isin(active_users)]\n",
    "\n",
    "# 2. Retain books that have been rated by enough users (at least 5 users)\n",
    "book_counts = filtered_ratings['ISBN'].value_counts()\n",
    "popular_books = book_counts[book_counts >= 5].index\n",
    "filtered_ratings = filtered_ratings[filtered_ratings['ISBN'].isin(popular_books)]\n",
    "\n",
    "# 3. Retain only high-rated data (ratings above 7)\n",
    "filtered_ratings = filtered_ratings[filtered_ratings['Book-Rating'] >= 7]\n",
    "\n",
    "# Sample data\n",
    "sampled_ratings = filtered_ratings.sample(n=5000, random_state=42)\n",
    "sampled_book_isbns = sampled_ratings['ISBN'].unique()\n",
    "\n",
    "# Create ISBN to index mapping\n",
    "isbn_to_idx = {isbn: idx for idx, isbn in enumerate(books['ISBN'])}\n",
    "idx_to_isbn = {idx: isbn for isbn, idx in isbn_to_idx.items()}\n",
    "\n",
    "#  Step 2: Prepare data in the format required by the Surprise library\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(sampled_ratings[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "trainset, testset = surprise_train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Use SVD model\n",
    "print(\"Training SVD model...\")\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Step 4: Use BERT model to get book title embeddings\n",
    "def get_bert_embeddings(titles):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "    \n",
    "    embeddings = []\n",
    "    for title in tqdm(titles, desc=\"Tokenizing titles\"):\n",
    "        if isinstance(title, str):  # Ensure the title is a string\n",
    "            inputs = tokenizer(title, padding=True, truncation=True, return_tensors=\"pt\", max_length=128).to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            embeddings.append(outputs.last_hidden_state[:, 0, :].cpu().numpy())\n",
    "        else:\n",
    "            # For non-string titles, use zero vectors\n",
    "            embeddings.append(np.zeros((1, 768)))\n",
    "    \n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Get BERT embeddings for all book titles\n",
    "print(\"Getting BERT embeddings for book titles...\")\n",
    "# Process only the sampled books\n",
    "sampled_books = books[books['ISBN'].isin(sampled_book_isbns)]\n",
    "book_titles = sampled_books['Book-Title'].tolist()\n",
    "book_embeddings = get_bert_embeddings(book_titles)\n",
    "\n",
    "# Compute cosine similarity matrix for book titles\n",
    "cosine_sim = cosine_similarity(book_embeddings, book_embeddings)\n",
    "\n",
    "# Step 5: Define content-based recommendation function\n",
    "def recommend_books_based_on_content(user_id, num_recommendations=5):\n",
    "    # Get books rated by the user\n",
    "    user_rated_books = sampled_ratings[sampled_ratings['User-ID'] == user_id]['ISBN'].tolist()\n",
    "    \n",
    "    # Get indices of rated books in the sampled dataset\n",
    "    rated_books_indices = []\n",
    "    for isbn in user_rated_books:\n",
    "        if isbn in sampled_books['ISBN'].values:\n",
    "            idx = sampled_books[sampled_books['ISBN'] == isbn].index[0]\n",
    "            rated_books_indices.append(idx - sampled_books.index[0])  # Adjust index to match cosine_sim matrix\n",
    "    \n",
    "    # Store all recommendations\n",
    "    content_based_recommendations = []\n",
    "    \n",
    "    for idx in rated_books_indices:\n",
    "        if idx < len(cosine_sim):  # Ensure the index is within range\n",
    "            similar_books = list(enumerate(cosine_sim[idx]))\n",
    "            similar_books = sorted(similar_books, key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            for book_idx, sim_score in similar_books[1:]:  # Skip itself\n",
    "                if book_idx < len(sampled_books):\n",
    "                    isbn = sampled_books.iloc[book_idx]['ISBN']\n",
    "                    if isbn not in user_rated_books:\n",
    "                        content_based_recommendations.append((isbn, sim_score))\n",
    "    \n",
    "    # Sort by similarity and return recommendations\n",
    "    content_based_recommendations = sorted(content_based_recommendations, key=lambda x: x[1], reverse=True)\n",
    "    recommended_isbns = [isbn for isbn, _ in content_based_recommendations[:num_recommendations]]\n",
    "    recommended_books = sampled_books[sampled_books['ISBN'].isin(recommended_isbns)]\n",
    "    \n",
    "    return recommended_books\n",
    "\n",
    "# Step 6: Define collaborative filtering recommendation function\n",
    "def recommend_books_for_user(user_id, num_recommendations=5):\n",
    "    user_rated_books = sampled_ratings[sampled_ratings['User-ID'] == user_id]['ISBN'].tolist()\n",
    "    books_to_predict = [isbn for isbn in sampled_book_isbns if isbn not in user_rated_books]\n",
    "    \n",
    "    predicted_ratings = []\n",
    "    for isbn in books_to_predict:\n",
    "        predicted_ratings.append((isbn, algo.predict(user_id, isbn).est))\n",
    "    \n",
    "    top_books = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "    recommended_books = sampled_books[sampled_books['ISBN'].isin([isbn for isbn, _ in top_books])]\n",
    "    return recommended_books\n",
    "\n",
    "# Step 7: Hybrid recommendation function\n",
    "def hybrid_recommend_books(user_id, num_recommendations=5, alpha=0.5):\n",
    "    try:\n",
    "        if user_id not in sampled_ratings['User-ID'].unique():\n",
    "            # Get the 5 books with the highest average rating\n",
    "            top_books = sampled_books.sort_values('Book-Rating', ascending=False).head(num_recommendations)\n",
    "            return top_books[['ISBN', 'Book-Title', 'Book-Author']]\n",
    "        collaborative_recommendations = recommend_books_for_user(user_id, num_recommendations)\n",
    "        content_based_recommendations = recommend_books_based_on_content(user_id, num_recommendations)\n",
    "        \n",
    "        # merge recommendation result\n",
    "        all_recommendations = pd.concat([collaborative_recommendations, content_based_recommendations])\n",
    "        all_recommendations = all_recommendations.drop_duplicates(subset=['ISBN'])\n",
    "        try:\n",
    "            return all_recommendations.sample(num_recommendations,random_state=42)\n",
    "        except Exception as e:\n",
    "            return all_recommendations.head(num_recommendations)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in hybrid_recommend_books for user {user_id}: {str(e)}\")\n",
    "        return pd.DataFrame(columns=['ISBN', 'Book-Title', 'Book-Author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba976db2-5fda-4d72-ae6a-4e21556a3edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating precision and recall...\n",
      "\n",
      "Calculating threshold 0.7...\n",
      "Threshold: 0.70\n",
      "Precision: 0.8557\n",
      "Recall: 0.9857\n",
      "F1-score: 0.9161\n",
      "\n",
      "Calculating threshold 0.75...\n",
      "Threshold: 0.75\n",
      "Precision: 0.8433\n",
      "Recall: 0.9713\n",
      "F1-score: 0.9028\n",
      "\n",
      "Calculating threshold 0.8...\n",
      "Threshold: 0.80\n",
      "Precision: 0.7637\n",
      "Recall: 0.8797\n",
      "F1-score: 0.8176\n",
      "\n",
      "Calculating threshold 0.85...\n",
      "Threshold: 0.85\n",
      "Precision: 0.5174\n",
      "Recall: 0.5960\n",
      "F1-score: 0.5539\n",
      "\n",
      "Calculating threshold 0.9...\n",
      "Threshold: 0.90\n",
      "Precision: 0.1741\n",
      "Recall: 0.2006\n",
      "F1-score: 0.1864\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 8: Evaluate the hybrid recommendation model\n",
    "def precision_recall_at_k(test_data, num_recommendations=5, sample_size=100, similarity_threshold=0.7):\n",
    "    hits, total_relevant, total_recommended = 0, 0, 0\n",
    "    \n",
    "    # Get the ISBN to index mapping for the sampled data\n",
    "    isbn_to_index = {isbn: idx for idx, isbn in enumerate(sampled_books['ISBN'])}\n",
    "    \n",
    "    # Only consider users who have rated books in the sampled data\n",
    "    test_data = test_data[test_data['ISBN'].isin(sampled_books['ISBN'])]\n",
    "    \n",
    "    # Randomly select users for evaluation\n",
    "    user_ids = test_data['User-ID'].unique()\n",
    "    if len(user_ids) > sample_size:\n",
    "        np.random.seed(42)\n",
    "        user_ids = np.random.choice(user_ids, sample_size, replace=False)\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        try:\n",
    "            # Get the user's ratings in the test set\n",
    "            user_test_ratings = test_data[test_data['User-ID'] == user_id]\n",
    "            if len(user_test_ratings) == 0:\n",
    "                continue\n",
    "                \n",
    "            avg_rating = user_test_ratings['Book-Rating'].mean()\n",
    "\n",
    "            # Get books the user likes (ratings above the average)\n",
    "            relevant_read_books = user_test_ratings[user_test_ratings['Book-Rating'] >= avg_rating]\n",
    "            relevant_read_books = pd.merge(relevant_read_books, sampled_books[['ISBN', 'Book-Title']], on='ISBN')\n",
    "            \n",
    "            if len(relevant_read_books) == 0:\n",
    "                continue\n",
    "\n",
    "            # Get books the user likes (ratings above the average)\n",
    "            # relevant_books = user_test_ratings[user_test_ratings['Book-Rating'] >= avg_rating]\n",
    "            # relevant_books = pd.merge(relevant_books, sampled_books[['ISBN', 'Book-Title']], on='ISBN')\n",
    "            \n",
    "            # if len(relevant_books) == 0:\n",
    "            #     continue\n",
    "                \n",
    "            # Calculate relevant books based on average ratings of all users\n",
    "            recommended_books = hybrid_recommend_books(user_id, num_recommendations)\n",
    "            if len(recommended_books) == 0:\n",
    "                continue\n",
    "            \n",
    "            relevant_books = pd.DataFrame(columns=recommended_books.columns)\n",
    "            for _, rec_book in recommended_books.iterrows():\n",
    "                rec_isbn = rec_book['ISBN']\n",
    "                avg_book_rating = test_data[test_data['ISBN'] == rec_isbn]['Book-Rating'].mean()\n",
    "                \n",
    "                if avg_book_rating > avg_rating:\n",
    "                    relevant_books = pd.concat([relevant_books, pd.DataFrame([rec_book])], ignore_index=True)  # 使用 pd.concat 替代 append\n",
    "            \n",
    "            if len(relevant_books) == 0:\n",
    "                continue\n",
    "\n",
    "            # print(\"rec\",len(recommended_books))\n",
    "            # print(\"rel\", len(relevant_books))\n",
    "            # Get recommended books\n",
    "            user_hits = 0\n",
    "\n",
    "            # for every recommanded book\n",
    "            for _, rec_book in relevant_books.iterrows():\n",
    "                if rec_book['ISBN'] not in isbn_to_index:\n",
    "                    continue\n",
    "                \n",
    "                rec_idx = isbn_to_index[rec_book['ISBN']]\n",
    "                counted = False\n",
    "                # for every book user liked (filter by average ratings)\n",
    "                for _, rel_book in relevant_read_books.iterrows():\n",
    "                    if rel_book['ISBN'] not in isbn_to_index:\n",
    "                        continue\n",
    "                        \n",
    "                    rel_idx = isbn_to_index[rel_book['ISBN']]\n",
    "                    \n",
    "                    # ensure the index is in the size of cosine_sim matrix\n",
    "                    if rec_idx >= len(cosine_sim) or rel_idx >= len(cosine_sim):\n",
    "                        continue\n",
    "                    \n",
    "                    # calculate the title similarity\n",
    "                    similarity = cosine_sim[rec_idx][rel_idx]\n",
    "                    \n",
    "                    # if the similarity is higher than the threshold, then hit\n",
    "                    if similarity >= similarity_threshold and counted == False:\n",
    "                        user_hits += 1\n",
    "                        counted = True\n",
    "                        break  # one book only counted to one hit\n",
    "            \n",
    "            hits += user_hits\n",
    "            total_relevant += len(relevant_books)\n",
    "            total_recommended += len(recommended_books)\n",
    "\n",
    "            # print(\"hits\",hits)\n",
    "            # print(\"total_relevant\",total_relevant)\n",
    "            # print(\"total_recommended\",total_recommended)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing user {user_id}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    precision = hits / total_recommended if total_recommended > 0 else 0\n",
    "    recall = hits / total_relevant if total_relevant > 0 else 0\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# Test different similarity threshold\n",
    "print(\"Calculating precision and recall...\")\n",
    "thresholds = [0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"\\nCalculating threshold {threshold}...\")\n",
    "    precision, recall = precision_recall_at_k(sampled_ratings, \n",
    "                                            num_recommendations=5, \n",
    "                                            sample_size=100, \n",
    "                                            similarity_threshold=threshold)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    })\n",
    "    print(f\"Threshold: {threshold:.2f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2d75373-9fa5-4fb1-a3a3-94a73a58e6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: 216343\n",
      "\n",
      "Books rated by the user:\n",
      "              ISBN                                         Book-Title\n",
      "105269  0060162546  Small Victories: The Real World of a Teacher, ...\n",
      "\n",
      "Books recommended for the user:\n",
      "             ISBN                                         Book-Title\n",
      "1105   0060928336    Divine Secrets of the Ya-Ya Sisterhood: A Novel\n",
      "14953  0553250426  The Clan of the Cave Bear (Earth's Children (P...\n",
      "1284   0380813815  Lamb : The Gospel According to Biff, Christ's ...\n",
      "1029   0345348036  The Princess Bride: S Morgenstern's Classic Ta...\n",
      "4244   0802130208           A Confederacy of Dunces (Evergreen Book)\n"
     ]
    }
   ],
   "source": [
    "# Randomly select a user ID from the sampled ratings\n",
    "random.seed(42)\n",
    "random_user_id = random.choice(sampled_ratings['User-ID'].unique())\n",
    "\n",
    "# Get the books rated by the selected user\n",
    "user_rated_books = sampled_ratings[sampled_ratings['User-ID'] == random_user_id]['ISBN'].tolist()\n",
    "\n",
    "# Get the books rated by the user with titles (join on ISBN)\n",
    "rated_books = sampled_books[sampled_books['ISBN'].isin(user_rated_books)]\n",
    "\n",
    "# Get the books recommended for this user using the hybrid recommendation system\n",
    "recommended_books = hybrid_recommend_books(random_user_id, num_recommendations=5)\n",
    "\n",
    "# Display the results\n",
    "print(f\"User ID: {random_user_id}\")\n",
    "print(\"\\nBooks rated by the user:\")\n",
    "\n",
    "# Display ISBN and Book-Rating for the books rated by the user, along with the Book Title\n",
    "rated_books_info = rated_books[['ISBN', 'Book-Title']]\n",
    "print(rated_books_info)\n",
    "\n",
    "print(\"\\nBooks recommended for the user:\")\n",
    "\n",
    "# Display ISBN and Book-Title for the recommended books\n",
    "print(recommended_books[['ISBN', 'Book-Title']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc10782-6862-41a5-b57a-b2493a5584e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
